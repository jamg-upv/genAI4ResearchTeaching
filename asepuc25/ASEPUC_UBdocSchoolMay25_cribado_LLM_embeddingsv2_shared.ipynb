{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "r2dZicdd5P7G",
        "-UO5F7yQ5bV5",
        "k4fyV1eh8uzx"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jamg-upv/genAI4ResearchTeaching/blob/main/asepuc25/ASEPUC_UBdocSchoolMay25_cribado_LLM_embeddingsv2_shared.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este codigo funciona con un entorno de de computacion de 12GB RAM sin GPU.\n",
        "Lo he probado con 4 categorias y 1300 abstracts a clasificar y con modelos de embeedings de 384 tokens no gasta más de 3Gb de ram. Con los 14 modelos (donde hay algunos de 1024 tokens) llega a gastar 6Gb (la ram depende de los tokens del modelo y no de la cantidad de objetos a embedd)\n",
        "los modelos de 384 tokens consumen unos 1-3 minutos por cada 600 abstracts\n",
        "Los modelosd e 720 tokens consumen unos 5-15 minutos por cada 600 abstracts\n"
      ],
      "metadata": {
        "id": "spIdvUXwcWiE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "vZ_ge4PTVeie"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparacion previa (ejecutar solo una vez)\n"
      ],
      "metadata": {
        "id": "X8FGO3RO7rWU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7BUJlZ-keFcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## (solo ejecutar si tus datos están en github y quieres importarlos) conexion a github"
      ],
      "metadata": {
        "id": "r2dZicdd5P7G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#conectar con repositorio github publico para acceso a los datasets (ajusta el nombre del repositorio al que corresponda)\n",
        "!git clone https://github.com/jamg-upv/LLMforSLRscreening.git\n",
        "\n",
        "# elije la carpeta del repositorio donde esta el archivo de datos   ACEDE-ECNwsDic24/\n",
        "# input_path = '/content/LLMforSLRscreening/datasets/'\n",
        "input_path = '/content/LLMforSLRscreening/ACEDE-ECNwsDic24/'\n",
        "\n",
        "# Define el nombre del archivo #Receuerda: estructura del archivo de datos:\n",
        "# Component\tDescription\tType\tClass\n",
        "input_file_name = 'ACEDE-ECN-workshop-dic-2024-HIWP3.csv'\n",
        "\n",
        "\n",
        "\n",
        "output_path = '/content/'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SD9kl1-cn-AW",
        "outputId": "ef22c4c9-e2ec-4194-90d9-b34d51a4dc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLMforSLRscreening'...\n",
            "remote: Enumerating objects: 460, done.\u001b[K\n",
            "remote: Counting objects: 100% (143/143), done.\u001b[K\n",
            "remote: Compressing objects: 100% (121/121), done.\u001b[K\n",
            "remote: Total 460 (delta 93), reused 20 (delta 20), pack-reused 317 (from 2)\u001b[K\n",
            "Receiving objects: 100% (460/460), 42.89 MiB | 11.71 MiB/s, done.\n",
            "Resolving deltas: 100% (230/230), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Solo ejecutar si quieres guardar los resultados en TU google drive)  googledrive montado en local"
      ],
      "metadata": {
        "id": "-UO5F7yQ5bV5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#conecar a google drive para guardar alli los outputs que quiera mantener (y que no se me olvide descargarlos) luego los subiré a Git para su uso posterior\n",
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Montar Google Drive si aún no está montado\n",
        "if not os.path.exists('/content/drive'):\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "# Define el path de salida en Google Drive\n",
        "output_path = '/content/drive/MyDrive/Reto21dias_24/'\n",
        "\n",
        "# Verifica si el directorio existe y si no, lo crea\n",
        "if not os.path.exists(output_path):\n",
        "    try:\n",
        "        os.makedirs(output_path)\n",
        "        print(f\"Directorio creado: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error al crear el directorio: {e}\")\n",
        "else:\n",
        "    print(f\"El directorio ya existe: {output_path}\")"
      ],
      "metadata": {
        "id": "SdqRhEZQ5jUE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "b5f8fea8-2345-4f08-9c2e-3d375673f45d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2-2511543883.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Montar Google Drive si aún no está montado\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Define el path de salida en Google Drive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    135\u001b[0m   )\n\u001b[1;32m    136\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    138\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Ruta a los archivos cargados y guardados en raiz de Colab (si se corta la conexion sin descargarlos se pierden)"
      ],
      "metadata": {
        "id": "2nRmVEZd5n8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define el nombre del archivo y el path de entrada y salida en raiz de google colab\n",
        "\n",
        "# estructura del archivo de datos input_file: # Component\tDescription\tType\tClass\n",
        "# input_file_name = 'ACEDE-ECN-workshop-dic-2024-HIWP3.csv'\n",
        "# input_file_name = 'ACEDE-ECN-workshop-dic-2024-HIWP.xlsx'\n",
        "input_file_name = 'UBschoolMay25-dataCribadoTransformersNewCat-SHORT.xlsx'\n",
        "\n",
        "input_path = '/content/'\n",
        "\n",
        "output_path = '/content/'"
      ],
      "metadata": {
        "id": "TLocOZAc5xe2"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parametrización de variables\n"
      ],
      "metadata": {
        "id": "xvXuHnNnSZZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os # Import the os module at the top of your script\n",
        "# Construye el path completo\n",
        "full_in_path = os.path.join(input_path, input_file_name)\n",
        "full_in_path\n",
        "# full_out_path = os.path.join(output_path, file_name)\n",
        "\n",
        "# Define la variable con el nombre de la columna\n",
        "target_column = 'Description'\n",
        "\n",
        "# Objetos a clasificar\n",
        "selec_objects = ['art1','art']\n",
        "# selec_objects = ['cat1']\n",
        "\n",
        "#categorias en la que quiero clasificar los objetos\n",
        "# selec_categories = ['cat3']\n",
        "selec_categories = ['cat1', 'cat2']\n",
        "\n",
        "# el identificador [component] de la categoria que quiero mostrar en el resumen de clasificación global\n",
        "\n",
        "# target_category ='promptB'\n",
        "target_category ='GOAL'\n"
      ],
      "metadata": {
        "id": "WVOoxtMCSpux"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# prueba (en desarrollo) para leer diferentes formatos de csv (no comprobada)"
      ],
      "metadata": {
        "id": "k4fyV1eh8uzx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def leer_archivo(ruta_archivo, **kwargs):\n",
        "    extension = ruta_archivo.split('.')[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if extension in ['xlsx', 'xls']:\n",
        "            return pd.read_excel(ruta_archivo, **kwargs)\n",
        "        elif extension == 'csv':\n",
        "            # Lista de configuraciones a intentar\n",
        "            configs = [\n",
        "                {'encoding': 'utf-8', 'sep': ','},\n",
        "                {'encoding': 'latin1', 'sep': ';'},\n",
        "                {'encoding': 'utf-8', 'sep': ';'},\n",
        "                {'encoding': 'cp1252', 'sep': ';'}  # Común en Windows\n",
        "            ]\n",
        "\n",
        "            # Intentar cada configuración\n",
        "            for config in configs:\n",
        "                try:\n",
        "                    # Combinar configuración predeterminada con kwargs\n",
        "                    params = {**config, **kwargs}\n",
        "                    return pd.read_csv(ruta_archivo, **params)\n",
        "                except:\n",
        "                    continue\n",
        "\n",
        "            raise ValueError(\"No se pudo leer el archivo CSV con ninguna configuración\")\n",
        "        else:\n",
        "            raise ValueError(f\"Formato de archivo no soportado: {extension}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Ejemplos de uso:\n",
        "# Lectura básica\n",
        "hiwp_data = leer_archivo(full_in_path)\n",
        "\n",
        "# Lectura con parámetros específicos\n",
        "# hiwp_data = leer_archivo(full_in_path, decimal=',', thousands='.')\n",
        "# hiwp_data = leer_archivo(full_in_path, sheet_name='Hoja1')  # Para Excel"
      ],
      "metadata": {
        "id": "Es1B4cfi7zBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# leer el archivo"
      ],
      "metadata": {
        "id": "UzfLid5W9DZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Leer el archivo CSV o EXCEL\n",
        "# Originalmente era un CSV de Open Office porque si lo generaba con MSexcel no se mapeaba bien )\n",
        "    # Para guardar correctamente un archivo CSV con comas desde OpenOffice cuando viene de Excel con punto y coma (;), sigue estos pasos:\n",
        "    # En OpenOffice, ve a \"Archivo → Guardar como\"\n",
        "    # Selecciona \"Texto CSV (.csv)\" como tipo de archivo\n",
        "    # Marca la casilla \"Editar configuración de filtro\"\n",
        "    # En la ventana de configuración:\n",
        "    # Juego de caracteres: Unicode (UTF-8)\n",
        "    # Delimitador de campo: selecciona \",\" (coma)\n",
        "    # Delimitador de texto: \" (comillas)\n",
        "    # NO se marca tener todas las cadenas de texto con \"\"\n",
        "#mejoro el codigo con esta funcion que debe gestionar automático el formato de CSV o de excel (la primera de las hojas del libro)\n",
        "\n",
        "def leer_archivo(ruta_archivo):\n",
        "    # Obtener la extensión del archivo\n",
        "    extension = ruta_archivo.split('.')[-1].lower()\n",
        "\n",
        "    try:\n",
        "        if extension in ['xlsx', 'xls']:\n",
        "            # Leer archivo Excel\n",
        "            return pd.read_excel(ruta_archivo)\n",
        "        elif extension == 'csv':\n",
        "            # Intentar primero con encoding UTF-8 y separador ','\n",
        "            try:\n",
        "                return pd.read_csv(ruta_archivo, encoding='utf-8')\n",
        "            except:\n",
        "                # Si falla, intentar con encoding latin1 y separador ';'\n",
        "                try:\n",
        "                    return pd.read_csv(ruta_archivo, encoding='latin1', sep=';')\n",
        "                except:\n",
        "                    # Último intento con encoding utf-8 y separador ';'\n",
        "                    return pd.read_csv(ruta_archivo, encoding='utf-8', sep=';')\n",
        "        else:\n",
        "            raise ValueError(f\"Formato de archivo no soportado: {extension}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error al leer el archivo: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# Uso de la funcion\n",
        "hiwp_data = leer_archivo(full_in_path)\n",
        "\n",
        "# hiwp_data = leer_archivo('/content/ART-749-dataCribadoTransformers.xlsx')\n",
        "# hiwp_data = pd.read_excel('/content/ART-749-dataCribadoTransformers.xlsx')\n",
        "hiwp_data\n",
        "# Verificar si la lectura fue exitosa\n",
        "if hiwp_data is not None:\n",
        "    print(\"Archivo leído correctamente\")\n",
        "    print(f\"Dimensiones del DataFrame: {hiwp_data.shape}\")\n",
        "else:\n",
        "    print(\"No se pudo leer el archivo\")\n",
        "\n",
        "# Mostrar el DataFrame resultante\n",
        "# print(hiwp_data)\n",
        "\n",
        "# Crear el DataFrame 'objects'\n",
        "objects = hiwp_data[hiwp_data['Type'].isin(selec_objects)]\n",
        "\n",
        "# Crear el DataFrame 'categories'\n",
        "categories = hiwp_data[hiwp_data['Type'].isin(selec_categories)]\n",
        "\n",
        "# Opción 1: Reconstruir el índice descartando el índice original\n",
        "# objects= objects.reset_index(drop=True)\n",
        "# categories= categories.reset_index(drop=True)\n",
        "\n",
        "# Opción 2: Reconstruir el índice manteniendo el índice original como una nueva columna\n",
        "objects= objects.reset_index()\n",
        "categories= categories.reset_index()\n",
        "\n",
        "\n",
        "# Verificar los resultados\n",
        "print(\"DataFrame 'objects':\")\n",
        "print(objects.shape)\n",
        "print(objects['Type'].value_counts())\n",
        "print(\"\\nPrimeras filas de 'objects':\")\n",
        "print(objects.head())\n",
        "\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
        "\n",
        "print(\"DataFrame 'categories':\")\n",
        "print(categories.shape)\n",
        "print(categories['Type'].value_counts())\n",
        "print(\"\\nPrimeras filas de 'categories':\")\n",
        "print(categories.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkStor1tSnr3",
        "outputId": "c686911f-6cc5-4311-a674-e11e10620fbb"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archivo leído correctamente\n",
            "Dimensiones del DataFrame: (198, 3)\n",
            "DataFrame 'objects':\n",
            "(194, 4)\n",
            "Type\n",
            "art    194\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras filas de 'objects':\n",
            "   index Component                                        Description Type\n",
            "0      4  id0001#0   Study on Data Analysis of Assessment in Class...  art\n",
            "1      5  id0012#0   Flipped pedagogy and student evaluations of t...  art\n",
            "2      6  id0021#0   ntegrity of Attitudes and Rating Tendencies o...  art\n",
            "3      7  id0022#2   Making Meaning from Student Evaluations of Te...  art\n",
            "4      8  id0024#0   Student evaluations of teaching (SET): Guidel...  art\n",
            "\n",
            "==================================================\n",
            "\n",
            "DataFrame 'categories':\n",
            "(4, 4)\n",
            "Type\n",
            "cat2    3\n",
            "cat1    1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Primeras filas de 'categories':\n",
            "   index  Component                                        Description  Type\n",
            "0      0       GOAL  Effects of open-ended questions in Student Eva...  cat1\n",
            "1      1        SLR  A systematic literature review (SLR) is a meth...  cat2\n",
            "2      2        SET  Student Evaluation of Teaching (SET) refers to...  cat2\n",
            "3      3  OpenEnded  Open-ended questions are a form of interrogati...  cat2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# CODIGO para Embeedings\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Djbdr5_wJvRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from importlib import metadata\n",
        "import subprocess\n",
        "import sys\n",
        "import importlib\n",
        "\n",
        "required_packages = [\n",
        "    'seaborn',\n",
        "    'matplotlib',\n",
        "    'sentence-transformers',\n",
        "    'pandas',\n",
        "    'numpy',\n",
        "    'transformers',\n",
        "    'torch',\n",
        "    'xlrd',\n",
        "    'openpyxl'\n",
        "]\n",
        "\n",
        "def get_installed_packages():\n",
        "    \"\"\"Obtiene una lista de paquetes instalados usando importlib.metadata\"\"\"\n",
        "    try:\n",
        "        return {dist.metadata['Name'].lower() for dist in metadata.distributions()}\n",
        "    except Exception:\n",
        "        return set()\n",
        "\n",
        "def install_packages():\n",
        "    installed_packages = get_installed_packages()\n",
        "    packages_to_install = [\n",
        "        pkg for pkg in required_packages\n",
        "        if pkg.lower().replace('-', '_') not in installed_packages\n",
        "    ]\n",
        "\n",
        "    if packages_to_install:\n",
        "        print(\"Instalando paquetes faltantes...\")\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\"] + packages_to_install)\n",
        "            print(\"\\nTodos los paquetes faltantes han sido instalados.\")\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"\\nError durante la instalación: {e}\")\n",
        "            return False\n",
        "    else:\n",
        "        print(\"Todos los paquetes requeridos ya están instalados.\")\n",
        "\n",
        "    return True\n",
        "\n",
        "def verify_installations():\n",
        "    print(\"\\nVerificando instalaciones:\")\n",
        "    all_installed = True\n",
        "    for package in required_packages:\n",
        "        try:\n",
        "            # Intentar importar el módulo\n",
        "            importlib.import_module(package.replace('-', '_'))\n",
        "            # Obtener la versión instalada\n",
        "            version = metadata.version(package)\n",
        "            print(f\"✓ {package} (versión {version})\")\n",
        "        except (ImportError, metadata.PackageNotFoundError):\n",
        "            print(f\"✗ {package} - No se pudo importar\")\n",
        "            all_installed = False\n",
        "    return all_installed\n",
        "\n",
        "def load_required_imports():\n",
        "    \"\"\"Función separada para cargar las importaciones necesarias\"\"\"\n",
        "    try:\n",
        "        # Realizar las importaciones globalmente\n",
        "        global SentenceTransformer, util, pd, np, torch, time\n",
        "        from sentence_transformers import SentenceTransformer, util\n",
        "        import pandas as pd\n",
        "        import numpy as np\n",
        "        import torch\n",
        "        import time\n",
        "        print(\"\\nTodas las importaciones completadas con éxito.\")\n",
        "        return True\n",
        "    except ImportError as e:\n",
        "        print(f\"\\nError al importar las bibliotecas: {e}\")\n",
        "        return False\n",
        "\n",
        "def main():\n",
        "    # Ejecutar instalación y verificación\n",
        "    if install_packages() and verify_installations():\n",
        "        print(\"\\nProcediendo con las importaciones...\")\n",
        "        return load_required_imports()\n",
        "    else:\n",
        "        print(\"\\nHubo problemas con la instalación o verificación de paquetes.\")\n",
        "        return False\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    success = main()\n",
        "    if success:\n",
        "        # Aquí ya puedes usar SentenceTransformer y demás imports\n",
        "        print(\"Sistema listo para usar\")"
      ],
      "metadata": {
        "id": "irPyxNC-_8uw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de3aadcd-8142-48af-da6a-e34d443525f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Instalando paquetes faltantes...\n",
            "\n",
            "Todos los paquetes faltantes han sido instalados.\n",
            "\n",
            "Verificando instalaciones:\n",
            "✓ seaborn (versión 0.13.2)\n",
            "✓ matplotlib (versión 3.10.0)\n",
            "✓ sentence-transformers (versión 4.1.0)\n",
            "✓ pandas (versión 2.2.2)\n",
            "✓ numpy (versión 2.0.2)\n",
            "✓ transformers (versión 4.53.0)\n",
            "✓ torch (versión 2.6.0+cu124)\n",
            "✓ xlrd (versión 2.0.2)\n",
            "✓ openpyxl (versión 3.1.5)\n",
            "\n",
            "Procediendo con las importaciones...\n",
            "\n",
            "Todas las importaciones completadas con éxito.\n",
            "Sistema listo para usar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "# Obtener la fecha y hora actual para etiquear hora del analisis en los nombres de archivo\n",
        "current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
      ],
      "metadata": {
        "id": "bCdIE0naMMCH"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de modelos a probar\n",
        "# Seleccion de los 1 de los rapidos entre los 5 mejores del articulo WPOM 2024\n",
        "# models_to_test = [\n",
        "#     'all-MiniLM-L6-v2'\n",
        "# ]\n",
        "\n",
        "# todos los modelos\n",
        "# models_to_test = [\n",
        "#     'all-MiniLM-L6-v2',\n",
        "#     'all-distilroberta-v1',\n",
        "#     'all-mpnet-base-v2',\n",
        "#     'paraphrase-multilingual-mpnet-base-v2',\n",
        "#     'distiluse-base-multilingual-cased-v1',\n",
        "#     'all-MiniLM-L12-v2',\n",
        "#     'allenai-specter',\n",
        "#     'allenai/scibert_scivocab_uncased',\n",
        "#     'distilbert-base-nli-mean-tokens',\n",
        "#     'roberta-base-nli-stsb-mean-tokens',\n",
        "#     'distiluse-base-multilingual-cased-v2',\n",
        "#     'paraphrase-multilingual-MiniLM-L12-v2',\n",
        "#     'stsb-roberta-large',\n",
        "#     'bert-base-nli-mean-tokens'\n",
        "#     'BAAI/bge-large-en-v1.5',    # 1024D - Top choice\n",
        "#     'intfloat/e5-large-v2',      # 1024D - Alternativa sólida\n",
        "#     'sentence-transformers/gtr-t5-large',      # Bueno para académicos\n",
        "#     'allenai/specter2_proximity' #ideal para cribado de revisiones sistemáticas de literatura (SLR), ya que está específicamente diseñado para trabajar con documentos científicos.\n",
        "# ]\n",
        "\n",
        "# Seleccion de los 5 mejores del articulo WPOM 2024\n",
        "models_to_test = [\n",
        "    'all-MiniLM-L6-v2'\n",
        "    # 'all-distilroberta-v1',\n",
        "    # 'all-mpnet-base-v2',\n",
        "    # 'all-MiniLM-L12-v2',\n",
        "    # 'allenai-specter',\n",
        "    # 'BAAI/bge-large-en-v1.5',    # 1024D - Top choice\n",
        "    #  'allenai/specter2_proximity' # pendiente de parametrizar para que funcione specter ideal para cribado de revisiones sistemáticas de literatura (SLR), ya que está específicamente diseñado para trabajar con documentos científicos.\n",
        "\n",
        "]\n",
        "\n",
        "# Seleccion de los peores del articulo WPOM 2024\n",
        "# models_to_test = [\n",
        "#     'paraphrase-multilingual-mpnet-base-v2',\n",
        "#     'distiluse-base-multilingual-cased-v1',\n",
        "#     'allenai/scibert_scivocab_uncased',\n",
        "#     'distilbert-base-nli-mean-tokens',\n",
        "#     'roberta-base-nli-stsb-mean-tokens',\n",
        "#     'distiluse-base-multilingual-cased-v2',\n",
        "#     'paraphrase-multilingual-MiniLM-L12-v2',\n",
        "#     'stsb-roberta-large',\n",
        "#     'bert-base-nli-mean-tokens'\n",
        "# ]\n",
        "\n",
        "# Función para evaluar un modelo\n",
        "def evaluate_model(model_name, objects_df, categories_df):\n",
        "    print(f\"Evaluating model: {model_name}\")\n",
        "    model = SentenceTransformer(model_name)\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Generar embeddings para objetos\n",
        "    object_texts = objects_df[target_column].tolist()\n",
        "    object_embeddings = model.encode(object_texts, show_progress_bar=True)\n",
        "\n",
        "    # Generar embeddings para categorías\n",
        "    category_texts = categories_df[target_column].tolist()\n",
        "    category_embeddings = model.encode(category_texts, show_progress_bar=True)\n",
        "\n",
        "    # Calcular similitud coseno\n",
        "    similarity_matrix = util.cos_sim(object_embeddings, category_embeddings)\n",
        "\n",
        "    # Encontrar las mejores coincidencias\n",
        "    best_matches = np.argmax(similarity_matrix, axis=1)\n",
        "\n",
        "    end_time = time.time()\n",
        "    processing_time = end_time - start_time\n",
        "\n",
        "    return {\n",
        "        'model': model_name,\n",
        "        'best_matches': categories_df.iloc[best_matches]['Component'].tolist(),\n",
        "        'processing_time': round(processing_time, 2),  # Redondear a 2 decimales\n",
        "        'embedding_size': object_embeddings.shape[1],\n",
        "        'similarity_matrix': similarity_matrix,\n",
        "        'object_embeddings': object_embeddings,\n",
        "        'category_embeddings': category_embeddings\n",
        "    }\n",
        "\n",
        "# Evaluar todos los modelos\n",
        "results = []\n",
        "similarity_data = []\n",
        "embeddings_data = []\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    try:\n",
        "        result = evaluate_model(model_name, objects, categories)\n",
        "        results.append({\n",
        "            'model': result['model'],\n",
        "            'best_matches': result['best_matches'],\n",
        "            'processing_time': result['processing_time'],\n",
        "            'embedding_size': result['embedding_size']\n",
        "        })\n",
        "\n",
        "        # Preparar datos de similitud para este modelo\n",
        "        for i, obj in enumerate(objects['Component']):\n",
        "            row = [model_name, obj] + result['similarity_matrix'][i].tolist()\n",
        "            similarity_data.append(row)\n",
        "\n",
        "        # Preparar datos de embeddings para este modelo\n",
        "        for i, obj in enumerate(objects['Description']):\n",
        "            embeddings_data.append([model_name, objects['Component'].iloc[i], obj, result['object_embeddings'][i].tolist()])\n",
        "        for i, cat in enumerate(categories['Description']):\n",
        "            embeddings_data.append([model_name, categories['Component'].iloc[i], cat, result['category_embeddings'][i].tolist()])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error evaluating {model_name}: {str(e)}\")\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results = df_results.rename(columns={'processing_time': 'processing_time_seconds'})\n",
        "print(df_results)\n",
        "\n",
        "# Crear DataFrame de similitud coseno\n",
        "columns = ['Model', 'Object'] + categories['Component'].tolist()\n",
        "df_similarity = pd.DataFrame(similarity_data, columns=columns)\n",
        "\n",
        "# Crear DataFrame de embeddings\n",
        "df_embeddings = pd.DataFrame(embeddings_data, columns=['Model', 'Component', 'Description', 'Embedding'])\n",
        "\n",
        "# Crear la nueva tabla de similitud para HIWPshortDescription\n",
        "df_hiwp_similarity = df_similarity[['Model', 'Object', target_category]].copy()\n",
        "df_hiwp_similarity.columns = ['Model', 'Object_Description', 'Similarity']\n",
        "df_hiwp_similarity['Object_Component'] = objects['Component'].tolist() * len(models_to_test)\n",
        "df_hiwp_similarity = df_hiwp_similarity[['Model', 'Object_Component', 'Object_Description', 'Similarity']]\n",
        "df_hiwp_similarity = df_hiwp_similarity.sort_values(['Model', 'Similarity'], ascending=[True, False])\n"
      ],
      "metadata": {
        "id": "52Ci32ItW0xd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537,
          "referenced_widgets": [
            "ff4e0766705547a3bd50949f7b6e76e3",
            "14173568dd4c4d23b5670d11325e617a",
            "79ae1ed330664c1baa873a2ab3994b76",
            "612e573327174b5499f93ca6bd35493b",
            "f2265ea8c20140bc858032b34debdb77",
            "a4deb208948a4509a5fd1baae1acc086",
            "4953f94b8c534de6a8d85c47bb5f865b",
            "12362eb189cc42d691be14ea834710f5",
            "36638bb5aac34bbebaf266edc99d6f6e",
            "f6166dd50f9b41bf841b6d82d9f58b2c",
            "f18d7becf4ac4c6293d782f4a7d3da97",
            "5fe5620b60304bbc9359aa500d30d365",
            "d00f77541e284e5ea85a4e6411e8415c",
            "c91730894b004d1b9e5467cc658a3520",
            "8b2f61e158764fe1a286b943dbf17e88",
            "56544f4439b34c678ebca7295804b1f3",
            "37e3d59ae7d64ce5a0c15acd4a34c108",
            "8467852144c642eca28bf590e815a8e4",
            "87e318146c45405c98d37900d0e20a10",
            "09be4ff6766d4e9f9e175bcd4b8150eb",
            "730b1756b55c417ab125ae6051187f0c",
            "18c3450d008c4387bb53b3cdaf450a52",
            "33aefd46a1e14da1815db0fa8579d621",
            "bffca2038c424a689679c912c6a3add9",
            "bb10ebde2e9b4ee99311fc29d230d2e0",
            "b7ba3131d9c64df383a53e4a657d11cd",
            "a17ef641d6f242f8b862898446883aa8",
            "486deee29644469abc292d2be230c514",
            "3d48886b1d8944cf85f4776cb29dd29a",
            "d1c5e9f6ce9447918721285a07cb1f3a",
            "d82f32af8a124b279983a9c27a23d97e",
            "976cf4b33aee4100948db4a565288fc4",
            "66552589d62b430880b1f59893e494b4",
            "c1ed57d08a6548639b17497df95a9949",
            "d4e6cd0ccef049508398e688449164bc",
            "cd81269ab558404195fae92c4528fa99",
            "08a58ef3bcab4edab86858c07e3983ec",
            "fc68a215fdc941e196f2dd4bb068e9c8",
            "14f7f9ab188246779feb1889180bce5f",
            "8014bdb567864eddb4c3f1244c653d12",
            "9f0a92fd49cb4b518216ba080fbf26a4",
            "958c4d99236145a39f16e8765388ff01",
            "833539a1cb4f4eb4a9d10d4c03606978",
            "873691a9fd184c46b58077ac24d37cdc",
            "a6eeae078508403c80b74eccb8617ef6",
            "3163fbc11f38469bb6b6eb10369c89a3",
            "86b4438560494e8eb9dec9f6326826db",
            "a2d42c2d8be748a88e5ed0c70e6eec8e",
            "cc2f48b4d0f043518652b1f504ba0481",
            "b9edab0be0e04a1ab26d25aae3dee842",
            "5a586e908b284c279c5cb0739947d9f5",
            "df97180c6eea4aac968295ddf484b0e5",
            "eb3f90b01af4447b91bb5e1241dd969f",
            "cef829238d8b4f50bcb7c6ed3f7e0e3d",
            "90e2cea068914c038c79c7d463d70920",
            "2507e138792a40f59ac80d1eb123c836",
            "33f2e8aa15c14d909da1f9b17d73a10d",
            "131750e4748c4f329ad96e35f877bc21",
            "df368d9f749d4df5ae6c702dc8d7ba71",
            "76931eacd90f4e30939b907d8d0d0328",
            "dd910d4a917842d086ca69c6e18ddf0f",
            "aaab3389c2a44b6d9c0a35783b32649b",
            "b39526d49af84609a0c976b343bf3e60",
            "24c32cf7fa974745b26129db43afeeb4",
            "efb57f153fc94245b422d9649f64796c",
            "4085aa3a752148c69c471c07d1e1d14f",
            "12600193012446df9fc56919263e851c",
            "e3474cb1f5fc47b7ab8bea5b2d8b9f13",
            "9b75969f7cd44438887a1231b3359363",
            "3d53e20f22ec4392b02db75bc1f05acc",
            "2eb0c143103a464cbeba13091540f0a0",
            "261a54049e0b47d699b8ed0fba9f6407",
            "7ffd0c57fb364754b79f42a16a4b4f9f",
            "6d3837c30a3f4a36b1bc6dbdf8d8b202",
            "0f61c1680c854f2098685ad0c2dac7fb",
            "18b35624ef3a467d94f3108f821c9f72",
            "2c814504369a413ab0d79758f9064cbb",
            "4eda95f6afc3498bb06ffa2a2d5ba8ac",
            "8046df5d41e943e09e00cb8c0d94ee2b",
            "a887a414e5c04de6938d96f1bbd58518",
            "385c3952442f4281a9e7a2c2c62e57c4",
            "b3ee5e7316c84db78677ed26eb169cdf",
            "fa579c1b42cd4c2599a398e6ae123600",
            "b28975e75ae949fe9dc028c5817836cb",
            "d626d3d44d454962b51b21afd0081575",
            "f04039f83ecc49ec841030347a9f4637",
            "68de03ffd25b43748ced93f82f7b97bb",
            "2b4771a844844a43a54c8a23d247ad2f",
            "5e25285f0c3042eb8815b7dc236d97e9",
            "8f16cc5b123d4a44bd3110b05fd19c8d",
            "a670bfef711a4db587d972e4625b05cc",
            "4ae97bba358944f09d9b97a6adc33843",
            "91a493a0381943c489c4331f01be2590",
            "6a97d8451b114a6dbe4599c8b9306709",
            "11940a604b8e415683030ca0646848f6",
            "4ce0587c27284131a3203dd5917cc1f9",
            "6cd42932f62e4dcb83f8a72f59ba15b9",
            "7ac97d2863424b8a847b5b234f3e64b6",
            "d63c467c7574450995b03335fbbfa338",
            "f7756d14029f4a4b96aef0b38093bc77",
            "aa1da0195f4045b994cba00b6799d0b6",
            "0307db116d594941b125dce1fd051eba",
            "3feed8a403a54f608ee121a0221259bb",
            "0dc03f86fdc043e3a1636c0a7ceda870",
            "7b135f4e14f849c6bcf91a4f6cf8e697",
            "eacdb7481158433c8e5a91e25466b306",
            "68b4b87cbda74c97a763f07d4117e38b",
            "6d76032043f14ba5ab7fd6c7822e0928",
            "7b6f41ace242485bbbb31ad94523c6b9",
            "f4aaf08dcdc6480ca1b1508079fc574a",
            "285b852b6aa248399e2aace17d378a64",
            "dd8ba0dde6ff439a95b00b8053bb79d0",
            "c7df3b8ad03547ca88916c90ce783542",
            "70587a582a874c66abcea112e91fd89b",
            "1133d959130d445c9f4618454412de55",
            "f3b691d8cb8949f18b4fdce7e571ae39",
            "0b9c32b8b03d446380df43e781d37348",
            "f07b22e8b5b6469b9d40e541843191cf",
            "a080b61b6e8f499eb88477588d2e722e",
            "e03b9777cc514aeaa86afca14aec7fc8",
            "8ea500e9906d45b2ad186bf167ed4032",
            "075c6605577647ddbe7358160284a981",
            "a5255e2ebd4345b3ae98478170254025",
            "fa275517739e4177a620904c8515c158",
            "417a4eaad1b3412193bf13d5fdeb2edc",
            "26b84ba86eb2401b90fb21078ae406cb",
            "5aedd35ef5d34a1ca05236a64a892eeb",
            "25c795cac42d406a892b861ed09db523",
            "7e7e53b51e604d789fc1170a3b2a63c6",
            "6771204c35b74c27a6ac6e9a7e4ae119",
            "7a64e2d0ba4e4e68a723464897480baa",
            "d7d81b21f7b74f3d97ed84858291f5a9",
            "8a52902825744a63a1f5360b6b7075e5",
            "9f59a5f4d93b4948a0efe74e01bf835e",
            "b661e749fa184c4cac592a7aaa90b744",
            "555b8f977fa34e5eaad7de5fc3c29412",
            "bafc58cd4c714bdd82912ced0008e4fb",
            "35cdc32d322b4bedb256efd8be7fc526",
            "cae27eaef35142f4900e32a7495ce576",
            "1cee50f357554f66a46be92a1ecb45bd",
            "594decfbd6e0431aace64adf5c1f8cdd",
            "424a44debdba4509ae1784eb3083c1e3",
            "5aad2c1f99ee40ac9a86fd56abe2c31f"
          ]
        },
        "outputId": "0171908f-5b35-41c3-8943-8158db2e5b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating model: all-MiniLM-L6-v2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff4e0766705547a3bd50949f7b6e76e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fe5620b60304bbc9359aa500d30d365"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33aefd46a1e14da1815db0fa8579d621"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1ed57d08a6548639b17497df95a9949"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a6eeae078508403c80b74eccb8617ef6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2507e138792a40f59ac80d1eb123c836"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "12600193012446df9fc56919263e851c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4eda95f6afc3498bb06ffa2a2d5ba8ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e25285f0c3042eb8815b7dc236d97e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f7756d14029f4a4b96aef0b38093bc77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "285b852b6aa248399e2aace17d378a64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/30 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "075c6605577647ddbe7358160284a981"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a52902825744a63a1f5360b6b7075e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              model                                       best_matches  \\\n",
            "0  all-MiniLM-L6-v2  [SET, SET, SET, SET, SET, SET, SET, SET, SET, ...   \n",
            "\n",
            "   processing_time_seconds  embedding_size  \n",
            "0                   108.58             384  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### opcional para modelos de alta dimensionalidad"
      ],
      "metadata": {
        "id": "241mTpPWeTQW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instalar PEFT para SPECTER2\n",
        "!pip install peft accelerate\n",
        "\n",
        "# Importar librerías adicionales\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "\n",
        "# Lista de modelos a probar - NUEVOS MODELOS DE ALTA DIMENSIONALIDAD\n",
        "# Comentarios sobre cada modelo para tu contexto de Management/Business:\n",
        "\n",
        "models_to_test = [\n",
        "    # 'BAAI/bge-large-en-v1.5',    # 1024D - Top choice para embeddings densos\n",
        "    # 'intfloat/e5-large-v2',      # 1024D - Alternativa sólida, excelente similitud semántica\n",
        "    # 'sentence-transformers/gtr-t5-large'      # Bueno para académicos, arquitectura T5\n",
        "    # 'allenai-specter',                    # SPECTER1 - más estable para SLR\n",
        "    'allenai/specter2_proximity' # Ideal para cribado SLR, específico para documentos científicos\n",
        "]\n",
        "\n",
        "# Si quieres comparar con tu baseline actual, descomenta esta línea:\n",
        "models_to_test.append('all-MiniLM-L6-v2')  # Tu modelo actual para comparación\n",
        "\n",
        "# Función para evaluar un modelo (optimizada para modelos grandes)\n",
        "def evaluate_model(model_name, objects_df, categories_df):\n",
        "    print(f\"Evaluating model: {model_name}\")\n",
        "\n",
        "    # Configuración específica para modelos grandes en Colab\n",
        "    torch.cuda.empty_cache()  # Limpiar memoria GPU si está disponible\n",
        "\n",
        "    try:\n",
        "        # Cargar modelo con configuraciones optimizadas para Colab\n",
        "        if 'specter2' in model_name:\n",
        "            print(\"Cargando SPECTER2 con configuración especial...\")\n",
        "            try:\n",
        "                # Método 1: Intentar carga directa con PEFT\n",
        "                model = SentenceTransformer(model_name, trust_remote_code=True)\n",
        "                print(\"SPECTER2 cargado correctamente con PEFT\")\n",
        "            except Exception as e1:\n",
        "                print(f\"Error método 1: {e1}\")\n",
        "                try:\n",
        "                    # Método 2: Cargar componentes por separado\n",
        "                    print(\"Intentando carga alternativa...\")\n",
        "                    from transformers import AutoTokenizer, AutoModel\n",
        "                    tokenizer = AutoTokenizer.from_pretrained('allenai/specter2_base', trust_remote_code=True)\n",
        "                    base_model = AutoModel.from_pretrained('allenai/specter2_base', trust_remote_code=True)\n",
        "\n",
        "                    # Crear SentenceTransformer a partir del modelo base\n",
        "                    from sentence_transformers import models\n",
        "                    word_embedding_model = models.Transformer(model_name_or_path='allenai/specter2_base')\n",
        "                    pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "                    model = SentenceTransformer(modules=[word_embedding_model, pooling_model])\n",
        "                    print(\"SPECTER2 cargado con método alternativo\")\n",
        "                except Exception as e2:\n",
        "                    print(f\"Error método 2: {e2}\")\n",
        "                    # Método 3: Fallback a SPECTER1\n",
        "                    print(\"Fallback a allenai-specter (versión anterior)\")\n",
        "                    model = SentenceTransformer('allenai-specter')\n",
        "                    model_name = 'allenai-specter'  # Actualizar nombre para resultados\n",
        "        else:\n",
        "            # Cargar otros modelos normalmente\n",
        "            model = SentenceTransformer(model_name)\n",
        "\n",
        "        # Usar device automático (GPU si está disponible, sino CPU)\n",
        "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "        model = model.to(device)\n",
        "\n",
        "        print(f\"Modelo cargado en: {device}\")\n",
        "        print(f\"Dimensiones del embedding: {model.get_sentence_embedding_dimension()}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error cargando modelo {model_name}: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    try:\n",
        "        # Generar embeddings para objetos con batch size optimizado para Colab\n",
        "        object_texts = objects_df[target_column].tolist()\n",
        "        object_embeddings = model.encode(\n",
        "            object_texts,\n",
        "            show_progress_bar=True,\n",
        "            batch_size=4,  # Reducido para modelos grandes\n",
        "            convert_to_tensor=True,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Generar embeddings para categorías\n",
        "        category_texts = categories_df[target_column].tolist()\n",
        "        category_embeddings = model.encode(\n",
        "            category_texts,\n",
        "            show_progress_bar=True,\n",
        "            batch_size=4,  # Reducido para modelos grandes\n",
        "            convert_to_tensor=True,\n",
        "            device=device\n",
        "        )\n",
        "\n",
        "        # Calcular similitud coseno\n",
        "        similarity_matrix = util.cos_sim(object_embeddings, category_embeddings)\n",
        "\n",
        "        # Convertir a numpy para compatibilidad con el resto del código\n",
        "        if torch.is_tensor(similarity_matrix):\n",
        "            similarity_matrix = similarity_matrix.cpu().numpy()\n",
        "        if torch.is_tensor(object_embeddings):\n",
        "            object_embeddings = object_embeddings.cpu().numpy()\n",
        "        if torch.is_tensor(category_embeddings):\n",
        "            category_embeddings = category_embeddings.cpu().numpy()\n",
        "\n",
        "        # Encontrar las mejores coincidencias\n",
        "        best_matches = np.argmax(similarity_matrix, axis=1)\n",
        "\n",
        "        end_time = time.time()\n",
        "        processing_time = end_time - start_time\n",
        "\n",
        "        # Limpiar memoria después de cada modelo\n",
        "        del model\n",
        "        torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "        return {\n",
        "            'model': model_name,\n",
        "            'best_matches': categories_df.iloc[best_matches]['Component'].tolist(),\n",
        "            'processing_time': round(processing_time, 2),\n",
        "            'embedding_size': object_embeddings.shape[1],\n",
        "            'similarity_matrix': similarity_matrix,\n",
        "            'object_embeddings': object_embeddings,\n",
        "            'category_embeddings': category_embeddings\n",
        "        }\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error durante el procesamiento con {model_name}: {str(e)}\")\n",
        "        # Limpiar memoria en caso de error\n",
        "        try:\n",
        "            del model\n",
        "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "        except:\n",
        "            pass\n",
        "        return None\n",
        "\n",
        "# Evaluar todos los modelos (resto del código igual)\n",
        "results = []\n",
        "similarity_data = []\n",
        "embeddings_data = []\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Procesando modelo: {model_name}\")\n",
        "    print(f\"{'='*60}\")\n",
        "\n",
        "    try:\n",
        "        result = evaluate_model(model_name, objects, categories)\n",
        "\n",
        "        if result is not None:  # Solo procesar si el modelo se evaluó correctamente\n",
        "            results.append({\n",
        "                'model': result['model'],\n",
        "                'best_matches': result['best_matches'],\n",
        "                'processing_time': result['processing_time'],\n",
        "                'embedding_size': result['embedding_size']\n",
        "            })\n",
        "\n",
        "            # Preparar datos de similitud para este modelo\n",
        "            for i, obj in enumerate(objects['Component']):\n",
        "                row = [model_name, obj] + result['similarity_matrix'][i].tolist()\n",
        "                similarity_data.append(row)\n",
        "\n",
        "            # Preparar datos de embeddings para este modelo\n",
        "            for i, obj in enumerate(objects['Description']):\n",
        "                embeddings_data.append([model_name, objects['Component'].iloc[i], obj, result['object_embeddings'][i].tolist()])\n",
        "            for i, cat in enumerate(categories['Description']):\n",
        "                embeddings_data.append([model_name, categories['Component'].iloc[i], cat, result['category_embeddings'][i].tolist()])\n",
        "\n",
        "            print(f\"✅ {model_name} completado exitosamente\")\n",
        "            print(f\"   Dimensiones: {result['embedding_size']}D\")\n",
        "            print(f\"   Tiempo: {result['processing_time']}s\")\n",
        "        else:\n",
        "            print(f\"❌ {model_name} falló durante la evaluación\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Error crítico evaluando {model_name}: {str(e)}\")\n",
        "\n",
        "# Crear DataFrame con resultados (resto del código igual)\n",
        "if results:  # Solo crear DataFrame si hay resultados\n",
        "    df_results = pd.DataFrame(results)\n",
        "    df_results = df_results.rename(columns={'processing_time': 'processing_time_seconds'})\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(\"RESUMEN DE RESULTADOS:\")\n",
        "    print(f\"{'='*60}\")\n",
        "    print(df_results)\n",
        "\n",
        "    # Crear DataFrame de similitud coseno\n",
        "    columns = ['Model', 'Object'] + categories['Component'].tolist()\n",
        "    df_similarity = pd.DataFrame(similarity_data, columns=columns)\n",
        "\n",
        "    # Crear DataFrame de embeddings\n",
        "    df_embeddings = pd.DataFrame(embeddings_data, columns=['Model', 'Component', 'Description', 'Embedding'])\n",
        "\n",
        "    # Crear la nueva tabla de similitud para target_category\n",
        "    df_hiwp_similarity = df_similarity[['Model', 'Object', target_category]].copy()\n",
        "    df_hiwp_similarity.columns = ['Model', 'Object_Description', 'Similarity']\n",
        "    df_hiwp_similarity['Object_Component'] = objects['Component'].tolist() * len([r['model'] for r in results])\n",
        "    df_hiwp_similarity = df_hiwp_similarity[['Model', 'Object_Component', 'Object_Description', 'Similarity']]\n",
        "    df_hiwp_similarity = df_hiwp_similarity.sort_values(['Model', 'Similarity'], ascending=[True, False])\n",
        "\n",
        "    print(f\"\\n✅ Procesamiento completado para {len(results)} modelos\")\n",
        "else:\n",
        "    print(\"❌ No se pudieron evaluar ninguno de los modelos\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "7f4876e53ce54a2c9162b9655e2429d2",
            "09df43250a5d4f22abea778131297f9f",
            "1c1339cc505245ffa7b278e26b835028",
            "4d5db1cac24e45db960bec903d237821",
            "e2c4e1db20ad4a6c9b5ec463b7ba3d24",
            "7ba0167df29f4cb0993564406cf66c46",
            "bfa7b53e7f34446287faf31c935197de",
            "46077ec5495d4452bac881bc350a975d",
            "2806c68cc45348509f4643cb849fc9cd",
            "2a882a005d934d67858b088025a8532b",
            "61a1055f25c74fcd8f48c523ab5983d2",
            "750215c825734d5d931a4b10acea420c",
            "348d4b3f4b724badaed96f931b98d926",
            "9e1dc8fe249a431dbc4fc8b670865f54",
            "64dc4f5b8b04465688cdd029e29d4388",
            "03ce3167137b432c8706ba932b777a82",
            "c1e5b58a6ec4485eb3989145f0c7e0f9",
            "abc524d757b647a5aa9e909b78615679",
            "96afadd59ec549caab5a809cf18f9cb7",
            "6126034268eb4c2884dbabf6e7b3d9e4",
            "9921f3bb059b4d64af55c4f42e0a6302",
            "dae85ac806e748f4993a06cf5a3b9ff5",
            "d68ed95ef70c44a1898076326de35b63",
            "e14e9c3a56ca490cadcefdf2b370b162",
            "8cafe4f48f6047319cd7d3ee6645c42d",
            "6057873f8a3e43afad009763bef519a5",
            "09e64954aee348a9aec931fb7b973707",
            "944fe5c5c49a4a9c88b5a94702e1574f",
            "d0d9aac2cc8243c6b148273ff4a25f5f",
            "e42aec24d3954c93b54cd1d5412527d4",
            "6bcd7be9edb94b8c856c94637515339a",
            "df61b9f86b8e4446b59c4020d08f7268",
            "8e179eed2fa74645a192a72a97464b72",
            "6e6e24f22b714f9db498c7dabdc7ce34",
            "b4d51f6d37cb4b8598ec72b740f5a1cb",
            "9e0edf7458f6460c92479385201a86cb",
            "6ef75e9d36824808844ab1a7e22bdc0f",
            "16fee74a096b4edd8ea36269fe812986",
            "04de391718504e3d9b3a726af0014b87",
            "2e42fc2ea8284f1a8c7382923a4120db",
            "26046f373394421aa93984d0f0edd60d",
            "81662a631a7a431583a818b99cf91ea0",
            "4efb622d46834ba7a051d767591d7c37",
            "4e1e299f3c4f4331ae38460adafa9c0c"
          ]
        },
        "id": "AGXoqXPCeSzl",
        "outputId": "d9057a96-dfd7-4d71-a492-ea3ec862fa99"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.15.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from peft) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from peft) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from peft) (6.0.2)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.11/dist-packages (from peft) (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from peft) (4.53.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from peft) (4.67.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from peft) (0.5.3)\n",
            "Requirement already satisfied: huggingface_hub>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from peft) (0.33.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub>=0.25.0->peft) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.13.0->peft) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers->peft) (0.21.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface_hub>=0.25.0->peft) (2025.6.15)\n",
            "\n",
            "============================================================\n",
            "Procesando modelo: allenai/specter2_proximity\n",
            "============================================================\n",
            "Evaluating model: allenai/specter2_proximity\n",
            "Cargando SPECTER2 con configuración especial...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name allenai/specter2_proximity. Creating a new one with mean pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error método 1: The PeftConfig config that is trying to be loaded is missing required keys: {'peft_type'}.\n",
            "Intentando carga alternativa...\n",
            "SPECTER2 cargado con método alternativo\n",
            "Modelo cargado en: cpu\n",
            "Dimensiones del embedding: 768\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f4876e53ce54a2c9162b9655e2429d2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "750215c825734d5d931a4b10acea420c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ allenai/specter2_proximity completado exitosamente\n",
            "   Dimensiones: 768D\n",
            "   Tiempo: 149.16s\n",
            "\n",
            "============================================================\n",
            "Procesando modelo: all-MiniLM-L6-v2\n",
            "============================================================\n",
            "Evaluating model: all-MiniLM-L6-v2\n",
            "Modelo cargado en: cpu\n",
            "Dimensiones del embedding: 384\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/49 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d68ed95ef70c44a1898076326de35b63"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6e6e24f22b714f9db498c7dabdc7ce34"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ all-MiniLM-L6-v2 completado exitosamente\n",
            "   Dimensiones: 384D\n",
            "   Tiempo: 20.66s\n",
            "\n",
            "============================================================\n",
            "RESUMEN DE RESULTADOS:\n",
            "============================================================\n",
            "                        model  \\\n",
            "0  allenai/specter2_proximity   \n",
            "1            all-MiniLM-L6-v2   \n",
            "\n",
            "                                        best_matches  processing_time_seconds  \\\n",
            "0  [SET, SET, GOAL, GOAL, SET, GOAL, GOAL, SET, G...                   149.16   \n",
            "1  [SET, SET, SET, SET, SET, SET, SET, SET, SET, ...                    20.66   \n",
            "\n",
            "   embedding_size  \n",
            "0             768  \n",
            "1             384  \n",
            "\n",
            "✅ Procesamiento completado para 2 modelos\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## continuamos con el codigo normal"
      ],
      "metadata": {
        "id": "3pb7XSqcedsM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###OPCIONAL##### SOLO EJECUTAR para reahacer el analisis de proximidad con otra categoria como target sin tener que repetir los embeedings\n",
        "# el identificador [component] de la categoria que quiero mostrar en el resumen de clasificación global\n",
        "# target_category ='HIWPshortDescrip'\n",
        "# target_category ='Empowerment'\n",
        "# target_category ='WorkLifeBalance'\n",
        "# target_category ='RemoteWork'\n",
        "# target_category ='GrenHRM'\n",
        "# target_category ='OpMange'\n",
        "# target_category ='KaizenLong'\n",
        "# target_category ='KaizenCulture'\n",
        "# target_category ='promptA'\n",
        "# target_category ='SLR'\n",
        "target_category ='OpenEnded'\n",
        "# promptAscag promptAperf promptBscag promptBperfCa promptBperf promptBca\n",
        "\n",
        "# Crear la nueva tabla de similitud para la target_category\n",
        "df_hiwp_similarity = df_similarity[['Model', 'Object', target_category]].copy()\n",
        "df_hiwp_similarity.columns = ['Model', 'Object_Description', 'Similarity']\n",
        "df_hiwp_similarity['Object_Component'] = objects['Component'].tolist() * len(models_to_test)\n",
        "df_hiwp_similarity = df_hiwp_similarity[['Model', 'Object_Component', 'Object_Description', 'Similarity']]\n",
        "df_hiwp_similarity = df_hiwp_similarity.sort_values(['Model', 'Similarity'], ascending=[True, False])\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zs74EAWuYLNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcula el rango de similitud para cada modelo individualmente, donde el rango 1 es el mejor (mayor similitud).\n",
        "# Calcula el rango promedio para cada Object_Description a través de todos los modelos.\n",
        "# Ordena los objetos por su rango promedio (el más bajo es el mejor).\n",
        "# La tabla resumen final contendrá las siguientes columnas:\n",
        "# # Object_Component: El componente del objeto.\n",
        "# # Object_Description: La descripción del objeto.\n",
        "# # Average_Rank: El rango promedio del objeto a través de todos los modelos (más bajo es mejor).\n",
        "# Los objetos estarán ordenados por su rango promedio,\n",
        "# lo que  dará una visión integrada de cómo se comportan los objetos a clasificar, a través de todos los modelos,\n",
        "# en relación con la categoria sobre la que me interesa clasificarlos.\n",
        "\n",
        "# No es sencillo poner un punto de corte a partir del cual se consideran \"excluidos\" los objetos a clasificar.\n",
        "# de modo que se haría un escreening por titulo y abstract manual.\n",
        "# partiendo del orden de esta tabla hasta llegar aun  punto donde # haya varios seguidos sin seleccionar.\n",
        "# Momento en el que se podría parar el screening asistido por clasificacion automática.\n",
        "\n",
        "# Función para calcular el rango inverso (el más alto obtiene el rango 1)\n",
        "def inverse_rank(series):\n",
        "    return series.rank(ascending=False, method='min')\n",
        "\n",
        "# Calcular rangos para cada modelo\n",
        "df_ranks = df_hiwp_similarity.groupby('Model').apply(lambda x: x.assign(Rank=inverse_rank(x['Similarity']))).reset_index(drop=True)\n",
        "\n",
        "# Calcular el rango promedio para cada Object_Component a través de todos los modelos\n",
        "df_summary = df_ranks.groupby('Object_Component')['Rank'].mean().reset_index()\n",
        "df_summary = df_summary.rename(columns={'Rank': 'Average_Rank'})\n",
        "\n",
        "# Añadir la Description correspondiente a cada Component\n",
        "df_summary = df_summary.merge(objects[['Component', 'Description']], left_on='Object_Component', right_on='Component', how='left')\n",
        "\n",
        "# Ordenar por rango promedio (ascendente, ya que el rango más bajo es mejor)\n",
        "df_summary = df_summary.sort_values('Average_Rank')\n",
        "\n",
        "# Reordenar las columnas\n",
        "df_summary = df_summary[['Object_Component', 'Description', 'Average_Rank']]\n",
        "\n",
        "# Mostrar las primeras filas de la tabla resumen\n",
        "print(target_category)\n",
        "print(df_summary.head(20))"
      ],
      "metadata": {
        "id": "AFNE3e7c6NAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ee7c83e-a44a-4528-a411-eea0eb6a06e9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GOAL\n",
            "    Object_Component                                        Description  \\\n",
            "6           id0069#0   Student Evaluations of Teaching Tools A Quali...   \n",
            "4           id0024#0   Student evaluations of teaching (SET): Guidel...   \n",
            "172         id0631#1   Effectiveness of the Use of Open-Ended Questi...   \n",
            "132         id0526#1   Measuring Student Responses in and Instructor...   \n",
            "155         id0586#1   Playing the SET game: how teachers view the i...   \n",
            "27          id0241#2   Evaluating and Improving the Formative Use of...   \n",
            "44          id0308#0   How do Students and Faculty Consider Numerica...   \n",
            "75          id0384#0   Redesigning student evaluations of teaching: ...   \n",
            "14          id0127#2   Honesty on student evaluations of teaching: e...   \n",
            "32          id0255#1   We can work it out: faculty interpretation of...   \n",
            "43          id0305#2   Student evaluations of teaching and the devel...   \n",
            "72          id0378#1   Contribution of open-ended questions in stude...   \n",
            "188         id0682#0   Exploring the influence of student emotions a...   \n",
            "189         id0692#1   How Does Students' Negative Feedback Affect U...   \n",
            "86          id0403#1   Themes from Veterinary Student Evaluations of...   \n",
            "84          id0400#0   What are they trying to tell me? Large-scale ...   \n",
            "76          id0385#2   Animated process-transparency in student eval...   \n",
            "33          id0270#2   Student motivations, perceptions and opinions...   \n",
            "120         id0486#2   Student evaluations of teaching: perceptions ...   \n",
            "92          id0417#2   A Guide for Making Valid Interpretations of S...   \n",
            "\n",
            "     Average_Rank  \n",
            "6             3.5  \n",
            "4             3.5  \n",
            "172           4.5  \n",
            "132           5.0  \n",
            "155           6.5  \n",
            "27            8.0  \n",
            "44           10.0  \n",
            "75           14.0  \n",
            "14           17.5  \n",
            "32           18.0  \n",
            "43           18.5  \n",
            "72           20.0  \n",
            "188          20.0  \n",
            "189          20.0  \n",
            "86           21.5  \n",
            "84           21.5  \n",
            "76           23.0  \n",
            "33           24.5  \n",
            "120          25.0  \n",
            "92           26.5  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-24-4037176016.py:22: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
            "  df_ranks = df_hiwp_similarity.groupby('Model').apply(lambda x: x.assign(Rank=inverse_rank(x['Similarity']))).reset_index(drop=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# etiquetar los archivos con alguna información adcional\n",
        "# tag_file = tag_file\n",
        "# tag_file = 'best5 models'\n",
        "# tag_file = 'worst9 models'\n",
        "# tag_file = ''\n",
        "# tag_file = 'all models-articles'\n",
        "tag_file = 'DOEJUl25-DosModelos_spectet2_all-MiniLM-L6-v2'"
      ],
      "metadata": {
        "id": "ECVs3u4GYfMV"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# código para guardar todos los DataFrames en un único archivo Excel, con cada DataFrame en una hoja separada\n",
        "\n",
        "from openpyxl import Workbook\n",
        "from openpyxl.utils.dataframe import dataframe_to_rows\n",
        "\n",
        "# Asegurarse de que la carpeta de salida existe\n",
        "os.makedirs(output_path, exist_ok=True)\n",
        "\n",
        "# Crear el nombre del archivo Excel\n",
        "excel_filename = f'classification_{tag_file}_{target_category}_{current_time}.xlsx'\n",
        "excel_path = os.path.join(output_path, excel_filename)\n",
        "\n",
        "# Crear un ExcelWriter object\n",
        "with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
        "    # Guardar cada DataFrame en una hoja separada\n",
        "    df_results.to_excel(writer, sheet_name='model_comparison_results', index=False)\n",
        "    df_similarity.to_excel(writer, sheet_name='tablas_similitud_coseno', index=False)\n",
        "    df_embeddings.to_excel(writer, sheet_name='embeddings', index=False)\n",
        "    df_hiwp_similarity.to_excel(writer, sheet_name='hiwp_similarity', index=False)\n",
        "    df_summary.to_excel(writer, sheet_name='hiwp_similarity_summary', index=False)\n",
        "\n",
        "print(f\"Todos los resultados han sido guardados en {excel_path}\")"
      ],
      "metadata": {
        "id": "A2-Jj3-GrwW4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29943449-3857-4f08-fc60-673980cd572e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todos los resultados han sido guardados en /content/classification_DOEJUl25-DosModelos_spectet2_all-MiniLM-L6-v2_GOAL_20250706_215710.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "t-dRK7z2hBD5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OPCIONAL. un código que lea los embeddings del archivo Excel y los prepare para poder reutilizarlos con los chunks de codigo de...\n",
        "\n",
        "ACEDE-ECN-dic24-cribado_LLMhiwp_embeddingsv2-shared.ipynb\n",
        "(basado en ACEDE_ECN_dic24_cribado_LLMhiwp_embeddingsv2_shared.ipynb)\n",
        "\n",
        "Sin tnere que volver a calcular los embeddigns, que según el numero de objeto y modelo puedes consumir mucho tiempo (por ejemplo con 1024 tolens y 1200 objetos a vectorizar son unos 30 minutos, con un modelo de 384 tokesn son unos 3 minutos solamente)\n",
        "\n",
        "El dato de entrada datosembeddings.xlsx es el resultdo que guarda cualquiera de esos dos códigos\n",
        "\n",
        "TEngo que terener cargados los dataframe de objects y categories..."
      ],
      "metadata": {
        "id": "dS9bY3CiXwi1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyNpavQ5XjQT"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sentence_transformers import util\n",
        "import ast\n",
        "\n",
        "# Leer el archivo Excel\n",
        "# Para archivo .xls\n",
        "# df_embeddings = pd.read_excel('datosembeddings.xls', sheet_name='embeddings', engine='xlrd')\n",
        "\n",
        "# Para archivo .xlsx\n",
        "df_embeddings = pd.read_excel('ART-749-embeddings.xlsx', sheet_name='embeddings', engine='openpyxl')\n",
        "\n",
        "# Obtener la lista de modelos únicos del DataFrame de embeddings\n",
        "models_to_test = df_embeddings['Model'].unique().tolist()\n",
        "\n",
        "# Convertir los embeddings de string a lista de números\n",
        "df_embeddings['Embedding'] = df_embeddings['Embedding'].apply(ast.literal_eval)\n",
        "\n",
        "# Crear diccionario para almacenar los resultados\n",
        "results = []\n",
        "similarity_data = []\n",
        "\n",
        "# Procesar cada modelo\n",
        "for model_name in df_embeddings['Model'].unique():\n",
        "    # Filtrar datos para el modelo actual\n",
        "    model_data = df_embeddings[df_embeddings['Model'] == model_name]\n",
        "\n",
        "    # Separar embeddings de objetos y categorías\n",
        "    objects_data = model_data[model_data['Component'].isin(objects['Component'])]\n",
        "    categories_data = model_data[model_data['Component'].isin(categories['Component'])]\n",
        "\n",
        "    # Convertir embeddings a arrays numpy\n",
        "    object_embeddings = np.array(objects_data['Embedding'].tolist())\n",
        "    category_embeddings = np.array(categories_data['Embedding'].tolist())\n",
        "\n",
        "    # Calcular similitud coseno\n",
        "    similarity_matrix = util.cos_sim(object_embeddings, category_embeddings)\n",
        "\n",
        "    # Encontrar las mejores coincidencias\n",
        "    best_matches = np.argmax(similarity_matrix, axis=1)\n",
        "\n",
        "    # Guardar resultados\n",
        "    results.append({\n",
        "        'model': model_name,\n",
        "        'best_matches': categories.iloc[best_matches]['Component'].tolist(),\n",
        "        'embedding_size': object_embeddings.shape[1]\n",
        "    })\n",
        "\n",
        "    # Preparar datos de similitud para este modelo\n",
        "    for i, obj in enumerate(objects['Component']):\n",
        "        row = [model_name, obj] + similarity_matrix[i].tolist()\n",
        "        similarity_data.append(row)\n",
        "\n",
        "# Crear DataFrame con resultados\n",
        "df_results = pd.DataFrame(results)\n",
        "\n",
        "# Crear DataFrame de similitud coseno\n",
        "columns = ['Model', 'Object'] + categories['Component'].tolist()\n",
        "df_similarity = pd.DataFrame(similarity_data, columns=columns)\n",
        "\n",
        "# A partir de aquí puedes usar el código que ya tenías para crear df_hiwp_similarity\n",
        "df_hiwp_similarity = df_similarity[['Model', 'Object', target_category]].copy()\n",
        "df_hiwp_similarity.columns = ['Model', 'Object_Description', 'Similarity']\n",
        "df_hiwp_similarity['Object_Component'] = objects['Component'].tolist() * len(models_to_test)\n",
        "df_hiwp_similarity = df_hiwp_similarity[['Model', 'Object_Component', 'Object_Description', 'Similarity']]\n",
        "df_hiwp_similarity = df_hiwp_similarity.sort_values(['Model', 'Similarity'], ascending=[True, False])\n",
        "\n",
        "# continua con ###OPCIONAL##### SOLO EJECUTAR para reahacer el analisis de proximidad con otra categoria como target sin tener que repetir los embeedings\n",
        "# o con # Calcula el rango de similitud para cada modelo individualmente, donde el rango 1 es el mejor (mayor similitud).\n"
      ]
    }
  ]
}
